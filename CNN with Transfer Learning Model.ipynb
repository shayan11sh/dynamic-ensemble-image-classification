{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35d4pZd1AkO4"
      },
      "outputs": [],
      "source": [
        "#Model 2 with required results\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.data import Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Load dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# Function to preprocess and resize images\n",
        "def preprocess_images(images):\n",
        "    images = tf.expand_dims(images, -1)  # Add a channel dimension\n",
        "    images = tf.repeat(images, 3, axis=-1)  # Convert to RGB\n",
        "    images = tf.image.resize_with_pad(images, 96, 96)  # Resize images\n",
        "    return images / 255.0  # Normalize the images\n",
        "\n",
        "# Convert the datasets to TensorFlow Dataset objects\n",
        "def get_dataset(x, y, batch_size=32):\n",
        "    dataset = Dataset.from_tensor_slices((x, y))\n",
        "    dataset = dataset.map(lambda img, lbl: (preprocess_images(img), lbl), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    dataset = dataset.batch(batch_size).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "train_dataset = get_dataset(train_images, train_labels)\n",
        "test_dataset = get_dataset(test_images, test_labels)\n",
        "\n",
        "# Load a pre-trained MobileNetV2 model as a feature extractor\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(96, 96, 3))\n",
        "base_model.trainable = False\n",
        "\n",
        "# Attach a new classification head\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model using the dataset\n",
        "history = model.fit(train_dataset, epochs=10, validation_data=test_dataset)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_dataset)\n",
        "print(f\"Test Accuracy: {test_acc}\")\n",
        "\n",
        "# Predict the test dataset\n",
        "y_pred = model.predict(test_dataset)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Confusion matrix\n",
        "conf_matrix = confusion_matrix(test_labels, y_pred_classes)\n",
        "print(conf_matrix)\n",
        "\n",
        "# Classification report\n",
        "print(classification_report(test_labels, y_pred_classes))\n",
        "\n",
        "# Plotting training and validation accuracy\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Plotting training and validation loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plotting the confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap='Blues')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ]
    }
  ]
}