{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35d4pZd1AkO4"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, auc, classification_report\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import seaborn as sns\n",
        "\n",
        "# Load data and preprocess it\n",
        "def load_data():\n",
        "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "    x_train = x_train[..., tf.newaxis]\n",
        "    x_test = x_test[..., tf.newaxis]\n",
        "    y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "    y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "    return x_train, y_train, x_test, y_test\n",
        "\n",
        "# Define a simple Capsule Layer\n",
        "def CapsuleLayer(inputs, num_capsule, dim_capsule, routings):\n",
        "    x = layers.Dense(num_capsule * dim_capsule)(inputs)\n",
        "    x = layers.Reshape((num_capsule, dim_capsule))(x)\n",
        "    return layers.Lambda(lambda s: tf.sqrt(tf.reduce_sum(tf.square(s), axis=-1)))(x)\n",
        "\n",
        "# Build the CapsNet model\n",
        "def build_capsnet(input_shape):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    x = layers.Conv2D(64, (3, 3), activation='relu')(inputs)\n",
        "    x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
        "    x = layers.Flatten()(x)  # Flatten preserving batch-size\n",
        "    capsule_output = CapsuleLayer(x, num_capsule=10, dim_capsule=16, routings=3)\n",
        "    output = layers.Dense(10, activation='softmax')(capsule_output)\n",
        "    model = models.Model(inputs=inputs, outputs=output)\n",
        "    return model\n",
        "\n",
        "# Train the model\n",
        "def train_model(model, x_train, y_train, x_test, y_test, epochs=10, batch_size=64):\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=epochs, batch_size=batch_size)\n",
        "    return history\n",
        "\n",
        "# Load and preprocess data\n",
        "x_train, y_train, x_test, y_test = load_data()\n",
        "\n",
        "# Build and train the initial model\n",
        "print(\"Training initial model...\")\n",
        "model = build_capsnet(x_train.shape[1:])\n",
        "initial_history = train_model(model, x_train[:30000], y_train[:30000], x_test, y_test)\n",
        "\n",
        "# Save the initial trained model\n",
        "model.save('pretrained_capsnet.h5')\n",
        "\n",
        "# Load the pre-trained model and apply transfer learning\n",
        "print(\"Applying transfer learning...\")\n",
        "model = tf.keras.models.load_model('pretrained_capsnet.h5')\n",
        "\n",
        "# Optionally freeze layers or modify the model here\n",
        "for layer in model.layers[:-1]:  # Freeze all but the last layer\n",
        "    layer.trainable = False\n",
        "\n",
        "# Retrain on the entire data\n",
        "transfer_history = train_model(model, x_train, y_train, x_test, y_test)\n",
        "\n",
        "# Function to plot confusion matrix\n",
        "def plot_confusion_matrix(y_true, y_pred):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", linewidths=.5)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.ylabel('Actual Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.show()\n",
        "\n",
        "# Function to plot ROC curve\n",
        "def plot_roc_curve(y_test, y_pred):\n",
        "    # Binarize the output\n",
        "    y_test_binarized = label_binarize(y_test, classes=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
        "    n_classes = y_test_binarized.shape[1]\n",
        "\n",
        "    # Compute ROC curve and ROC area for each class\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc = dict()\n",
        "    for i in range(n_classes):\n",
        "        fpr[i], tpr[i], _ = roc_curve(y_test_binarized[:, i], y_pred[:, i])\n",
        "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "    # Plot all ROC curves\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    colors = iter(plt.cm.rainbow(np.linspace(0, 1, n_classes)))\n",
        "    for i, color in zip(range(n_classes), colors):\n",
        "        plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
        "                 label='ROC curve of class {0} (area = {1:0.2f})'.format(i, roc_auc[i]))\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic for multi-class')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "# Evaluate model\n",
        "print(\"Evaluating model...\")\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "y_true_labels = np.argmax(y_test, axis=1)\n",
        "plot_confusion_matrix(y_true_labels, y_pred_labels)\n",
        "plot_roc_curve(y_test, y_pred)\n",
        "print(classification_report(y_true_labels, y_pred_labels))\n"
      ]
    }
  ]
}